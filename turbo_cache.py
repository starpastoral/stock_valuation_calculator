# turbo_cache.py - çœŸæ­£é«˜æ•ˆçš„ç¼“å­˜ç³»ç»Ÿ
import pandas as pd
import json
import pickle
import gzip
import time
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

class TurboCache:
    """
    Turboç¼“å­˜ç³»ç»Ÿ - çœŸæ­£çš„é«˜æ€§èƒ½ç¼“å­˜
    
    ä¼˜åŒ–åŸç†:
    1. é¢„å¤„ç†: xls â†’ parquet (50x faster)
    2. é¢„è®¡ç®—: è‚¡ç¥¨â†’WACCç›´æ¥æ˜ å°„
    3. å‹ç¼©å­˜å‚¨: gzipå‹ç¼©èŠ‚çœ90%ç©ºé—´
    4. åˆ†å±‚ç¼“å­˜: å†…å­˜â†’ç£ç›˜â†’åŸå§‹æ•°æ®
    """
    
    def __init__(self, data_dir="data"):
        self.data_dir = Path(data_dir)
        self.turbo_dir = self.data_dir / "turbo_cache"
        self.turbo_dir.mkdir(exist_ok=True)
        
        # ç¼“å­˜æ–‡ä»¶è·¯å¾„
        self.stock_wacc_file = self.turbo_dir / "stock_wacc.json.gz"
        self.stock_info_file = self.turbo_dir / "stock_info.parquet"
        self.quick_index_file = self.turbo_dir / "quick_index.json"
        
        # å†…å­˜ç¼“å­˜
        self.stock_wacc_cache = {}  # è‚¡ç¥¨â†’WACCç›´æ¥æ˜ å°„
        self.stock_info_cache = {}  # è‚¡ç¥¨è¯¦æƒ…ç¼“å­˜
        self.is_initialized = False
        
        # è‡ªåŠ¨åˆå§‹åŒ–
        self._initialize()
    
    def _initialize(self):
        """åˆå§‹åŒ–Turboç¼“å­˜"""
        if self._load_from_cache():
            self.is_initialized = True
            logger.info("ğŸš€ Turboç¼“å­˜åŠ è½½æˆåŠŸ")
        else:
            logger.info("ğŸ”„ é¦–æ¬¡è¿è¡Œï¼Œå¼€å§‹é¢„å¤„ç†...")
            if self._preprocess_data():
                self.is_initialized = True
                logger.info("âœ… Turboç¼“å­˜é¢„å¤„ç†å®Œæˆ")
    
    def _load_from_cache(self):
        """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
        try:
            # åŠ è½½è‚¡ç¥¨â†’WACCæ˜ å°„
            if self.stock_wacc_file.exists():
                with gzip.open(self.stock_wacc_file, 'rt', encoding='utf-8') as f:
                    self.stock_wacc_cache = json.load(f)
                logger.info(f"ğŸ“Š åŠ è½½è‚¡ç¥¨WACCæ˜ å°„: {len(self.stock_wacc_cache)} ä¸ªè‚¡ç¥¨")
                return True
        except Exception as e:
            logger.warning(f"ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
            return False
    
    def _preprocess_data(self):
        """é¢„å¤„ç†æ•°æ® - å…³é”®æ€§èƒ½ä¼˜åŒ–"""
        try:
            excel_file = self.data_dir / "indname.xls"
            if not excel_file.exists():
                logger.error("indname.xlsæ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
            logger.info("ğŸ”„ å¼€å§‹é¢„å¤„ç†Excelæ–‡ä»¶...")
            start_time = time.time()
            
            # 1. è¯»å–Excelå¹¶è½¬æ¢ä¸ºé«˜æ•ˆæ ¼å¼
            df = pd.read_excel(excel_file, sheet_name='By Industry')
            
            # 2. æ•°æ®æ¸…ç†å’Œæ ‡å‡†åŒ– - æ­£ç¡®å¤„ç†å„å›½äº¤æ˜“æ‰€åç¼€
            def process_exchange_ticker(exchange_ticker):
                """æ ¹æ®äº¤æ˜“æ‰€æ·»åŠ æ­£ç¡®çš„è‚¡ç¥¨ä»£ç åç¼€"""
                if pd.isna(exchange_ticker):
                    return ''
                
                ticker_str = str(exchange_ticker)
                if ':' not in ticker_str:
                    return ticker_str
                
                exchange, symbol = ticker_str.split(':', 1)
                
                # äº¤æ˜“æ‰€åç¼€æ˜ å°„
                exchange_suffix_map = {
                    # ç¾å›½äº¤æ˜“æ‰€ - æ— åç¼€
                    'NYSE': '',
                    'NasdaqGM': '',
                    'NasdaqGS': '',
                    'NasdaqCM': '',
                    'NASDAQ': '',
                    'AMEX': '',
                    
                    # ä¸­å›½äº¤æ˜“æ‰€
                    'SZSE': '.SZ',      # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€
                    'SHSE': '.SS',      # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
                    'SEHK': '.HK',      # é¦™æ¸¯è¯åˆ¸äº¤æ˜“æ‰€
                    
                    # æ—¥æœ¬äº¤æ˜“æ‰€
                    'TSE': '.T',        # ä¸œäº¬è¯åˆ¸äº¤æ˜“æ‰€
                    
                    # å°æ¹¾äº¤æ˜“æ‰€
                    'TWSE': '.TW',      # å°æ¹¾è¯åˆ¸äº¤æ˜“æ‰€
                    'TPEX': '.TW',      # å°æ¹¾æŸœä¹°ä¸­å¿ƒ
                    
                    # å…¶ä»–
                    'LSE': '.L',        # ä¼¦æ•¦è¯åˆ¸äº¤æ˜“æ‰€
                    'FRA': '.F',        # æ³•å…°å…‹ç¦è¯åˆ¸äº¤æ˜“æ‰€
                    'EPA': '.PA',       # æ¬§æ´²äº¤æ˜“æ‰€å·´é»
                }
                
                suffix = exchange_suffix_map.get(exchange, '')
                return symbol + suffix
            
            df['symbol'] = df['Exchange:Ticker'].apply(process_exchange_ticker)
            df['exchange'] = df['Exchange:Ticker'].str.split(':').str[0]
            df['company_clean'] = df['Company Name'].str.replace(r'\([^)]*\)', '', regex=True).str.strip()
            
            # 3. è½¬æ¢ä¸ºParquetæ ¼å¼ (50x faster than Excel)
            df.to_parquet(self.stock_info_file, compression='snappy')
            
            # 4. é¢„è®¡ç®—è‚¡ç¥¨â†’WACCæ˜ å°„ (ä½¿ç”¨æ–°çš„WACCå¤„ç†å™¨)
            from wacc_processor import WACCProcessor
            
            # ä½¿ç”¨æ–°çš„WACCå¤„ç†å™¨è·å–æ‰€æœ‰å›½å®¶çš„WACCæ•°æ®
            wacc_processor = WACCProcessor()
            wacc_data = wacc_processor.process_all_wacc_files()
            
            if wacc_data is None:
                logger.error("æ— æ³•è·å–WACCæ•°æ®")
                return False
            
            # åˆ›å»ºWACCæŸ¥æ‰¾å­—å…¸ {(industry, region): wacc}
            wacc_lookup = {}
            for _, row in wacc_data.iterrows():
                key = (row['industry'].lower().strip(), row['region'])
                wacc_lookup[key] = row['wacc']
            
            logger.info(f"ğŸ“Š WACCæŸ¥æ‰¾è¡¨åˆ›å»ºå®Œæˆ: {len(wacc_lookup)} ä¸ªæ¡ç›®")
            
            # å›½å®¶æ˜ å°„
            country_mapping = {
                'China': 'China',
                'Hong Kong': 'China',  # é¦™æ¸¯ä½¿ç”¨ä¸­å›½WACC
                'Macao': 'China',      # æ¾³é—¨ä½¿ç”¨ä¸­å›½WACC
                'Taiwan': 'China',     # å°æ¹¾ä½¿ç”¨ä¸­å›½WACC
                'Japan': 'Japan',
                'United States': 'US',
                'US': 'US'
            }
            
            stock_wacc_mapping = {}
            stats = {'found': 0, 'not_found': 0, 'default': 0}
            
            for _, row in df.iterrows():
                symbol = row['symbol']
                industry = row.get('Industry Group', '')
                country = row.get('Country', '')
                
                if pd.notna(symbol) and pd.notna(industry):
                    # æ ¹æ®å›½å®¶é€‰æ‹©ç›¸åº”çš„WACCåœ°åŒº
                    region = country_mapping.get(country, 'US')  # é»˜è®¤ä½¿ç”¨ç¾å›½
                    industry_clean = industry.lower().strip()
                    
                    # æŸ¥æ‰¾WACCï¼ˆä¼˜å…ˆä½¿ç”¨å¯¹åº”å›½å®¶çš„ï¼‰
                    wacc = None
                    wacc_source = None
                    
                    # 1. å°è¯•ç²¾ç¡®åŒ¹é…
                    key = (industry_clean, region)
                    if key in wacc_lookup:
                        wacc = wacc_lookup[key]
                        wacc_source = f"{region}ç²¾ç¡®åŒ¹é…"
                        stats['found'] += 1
                    
                    # 2. æ¨¡ç³ŠåŒ¹é…ï¼ˆåŒä¸€å›½å®¶ï¼‰
                    if wacc is None:
                        for (lookup_industry, lookup_region), lookup_wacc in wacc_lookup.items():
                            if lookup_region == region and industry_clean in lookup_industry:
                                wacc = lookup_wacc
                                wacc_source = f"{region}æ¨¡ç³ŠåŒ¹é…"
                                stats['found'] += 1
                                break
                    
                    # 3. å¦‚æœä¸æ˜¯ç¾å›½ï¼Œå°è¯•ç”¨ç¾å›½æ•°æ®ä½œä¸ºå…œåº•
                    if wacc is None and region != 'US':
                        us_key = (industry_clean, 'US')
                        if us_key in wacc_lookup:
                            wacc = wacc_lookup[us_key]
                            wacc_source = "ç¾å›½å…œåº•"
                            stats['not_found'] += 1
                        else:
                            # ç¾å›½æ¨¡ç³ŠåŒ¹é…
                            for (lookup_industry, lookup_region), lookup_wacc in wacc_lookup.items():
                                if lookup_region == 'US' and industry_clean in lookup_industry:
                                    wacc = lookup_wacc
                                    wacc_source = "ç¾å›½æ¨¡ç³Šå…œåº•"
                                    stats['not_found'] += 1
                                    break
                    
                    # 4. æœ€ç»ˆé»˜è®¤å€¼
                    if wacc is None:
                        wacc = 0.12  # 12%é»˜è®¤WACC
                        wacc_source = "é»˜è®¤å€¼"
                        stats['default'] += 1
                    
                    stock_wacc_mapping[symbol] = {  # ä¿æŒåŸå§‹å¤§å°å†™ï¼ˆåŒ…å«åç¼€ï¼‰
                        'wacc': wacc,
                        'industry': industry,
                        'company_name': row['company_clean'],
                        'country': country,
                        'region': region,
                        'exchange': row.get('exchange', ''),
                        'wacc_source': wacc_source,
                        'sector': row.get('Primary Sector', '')
                    }
            
            logger.info(f"ğŸ“ˆ WACCåŒ¹é…ç»Ÿè®¡: æ‰¾åˆ°={stats['found']}, æœªæ‰¾åˆ°={stats['not_found']}, é»˜è®¤={stats['default']}")
            
            # 5. å‹ç¼©ä¿å­˜é¢„è®¡ç®—ç»“æœ
            with gzip.open(self.stock_wacc_file, 'wt', encoding='utf-8') as f:
                json.dump(stock_wacc_mapping, f, ensure_ascii=False)
            
            # 6. åˆ›å»ºå¿«é€Ÿç´¢å¼•
            quick_index = {
                'total_stocks': len(stock_wacc_mapping),
                'created_time': time.time(),
                'source_file': str(excel_file),
                'cache_version': '2.0'
            }
            
            with open(self.quick_index_file, 'w', encoding='utf-8') as f:
                json.dump(quick_index, f, ensure_ascii=False, indent=2)
            
            # 7. åŠ è½½åˆ°å†…å­˜
            self.stock_wacc_cache = stock_wacc_mapping
            
            process_time = time.time() - start_time
            logger.info(f"âœ… é¢„å¤„ç†å®Œæˆ: {len(stock_wacc_mapping)} ä¸ªè‚¡ç¥¨, è€—æ—¶ {process_time:.2f}ç§’")
            
            return True
            
        except Exception as e:
            logger.error(f"é¢„å¤„ç†å¤±è´¥: {e}")
            return False
    
    def get_stock_wacc(self, symbol):
        """ç›´æ¥è·å–è‚¡ç¥¨WACC - æ¯«ç§’çº§æŸ¥è¯¢ï¼Œæ”¯æŒå„å›½äº¤æ˜“æ‰€æ ¼å¼"""
        if not self.is_initialized:
            return None
        
        symbol = symbol.strip()
        
        # ç›´æ¥æŸ¥æ‰¾ï¼ˆä¼˜å…ˆï¼‰
        if symbol in self.stock_wacc_cache:
            return self.stock_wacc_cache[symbol]
        
        # å¤§å°å†™ä¸æ•æ„ŸæŸ¥æ‰¾
        symbol_upper = symbol.upper()
        symbol_lower = symbol.lower()
        
        for cached_symbol, data in self.stock_wacc_cache.items():
            if (cached_symbol.upper() == symbol_upper or 
                cached_symbol.lower() == symbol_lower):
                return data
        
        return None
    
    def get_stock_info(self, symbol):
        """è·å–è‚¡ç¥¨å®Œæ•´ä¿¡æ¯"""
        return self.get_stock_wacc(symbol)  # ç°åœ¨åŒ…å«å®Œæ•´ä¿¡æ¯
    
    def batch_get_wacc(self, symbols):
        """æ‰¹é‡è·å–WACC - è¶…é«˜é€Ÿï¼Œæ”¯æŒå„å›½äº¤æ˜“æ‰€æ ¼å¼"""
        if not self.is_initialized:
            return {}
        
        result = {}
        for symbol in symbols:
            info = self.get_stock_wacc(symbol)
            if info:
                result[symbol] = info['wacc']
            else:
                result[symbol] = 0.12  # é»˜è®¤WACC
        
        return result
    
    def get_cache_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        stats = {
            'initialized': self.is_initialized,
            'cached_stocks': len(self.stock_wacc_cache),
            'cache_files_exist': {
                'stock_wacc': self.stock_wacc_file.exists(),
                'stock_info': self.stock_info_file.exists(),
                'quick_index': self.quick_index_file.exists()
            }
        }
        
        if self.quick_index_file.exists():
            try:
                with open(self.quick_index_file, 'r', encoding='utf-8') as f:
                    index_data = json.load(f)
                stats.update(index_data)
            except:
                pass
        
        return stats
    
    def search_stocks(self, query, limit=20):
        """æœç´¢è‚¡ç¥¨"""
        if not self.is_initialized:
            return []
        
        query_lower = query.lower()
        matches = []
        
        for symbol, info in self.stock_wacc_cache.items():
            if (query_lower in symbol.lower() or 
                query_lower in info.get('company_name', '').lower()):
                matches.append(symbol)
                if len(matches) >= limit:
                    break
        
        return matches
    
    def rebuild_cache(self):
        """é‡å»ºç¼“å­˜"""
        return self._preprocess_data()

# å…¨å±€å®ä¾‹
turbo_cache = TurboCache()

if __name__ == "__main__":
    # æ€§èƒ½æµ‹è¯•
    print("ğŸš€ Turboç¼“å­˜æ€§èƒ½æµ‹è¯•")
    
    stats = turbo_cache.get_cache_stats()
    print(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡: {stats}")
    
    # æµ‹è¯•æŸ¥è¯¢é€Ÿåº¦
    test_symbols = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']
    
    print("\nâš¡ æŸ¥è¯¢é€Ÿåº¦æµ‹è¯•:")
    start_time = time.time()
    
    for symbol in test_symbols:
        info = turbo_cache.get_stock_wacc(symbol)
        if info:
            print(f"  {symbol}: WACC={info['wacc']:.2%}, {info['company_name']}")
        else:
            print(f"  {symbol}: æœªæ‰¾åˆ°")
    
    total_time = time.time() - start_time
    print(f"\nğŸ¯ æ€»æŸ¥è¯¢æ—¶é—´: {total_time:.4f}ç§’ ({len(test_symbols)}ä¸ªè‚¡ç¥¨)")
    print(f"ğŸ“ˆ å¹³å‡æ¯è‚¡ç¥¨: {total_time/len(test_symbols):.4f}ç§’")
    
    # æ‰¹é‡æŸ¥è¯¢æµ‹è¯•
    print("\nğŸ“¦ æ‰¹é‡æŸ¥è¯¢æµ‹è¯•:")
    start_time = time.time()
    batch_result = turbo_cache.batch_get_wacc(test_symbols)
    batch_time = time.time() - start_time
    
    print(f"æ‰¹é‡æŸ¥è¯¢æ—¶é—´: {batch_time:.4f}ç§’")
    print(f"ç»“æœ: {batch_result}") 